{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN vs Logistic Regression in Mnist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits().data\n",
    "images = load_digits().images\n",
    "targets = load_digits().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images.reshape(-1,64)\n",
    "y = targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.5,random_state=7)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978865406006674"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 89,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1, 85,  0,  0,  0,  0,  0,  2,  0],\n",
       "       [ 0,  0,  0, 86,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 85,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 82,  0,  0,  0,  1],\n",
       "       [ 0,  1,  0,  0,  0,  0, 91,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 91,  0,  0],\n",
       "       [ 0,  4,  1,  2,  0,  0,  0,  0, 93,  0],\n",
       "       [ 0,  0,  0,  3,  0,  1,  0,  0,  1, 83]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "c_matrix = confusion_matrix(y_test,model.predict(X_test))\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.978865406006674\n",
      "Precision 0: 1.0\n",
      "Precision 1: 1.0\n",
      "Precision 2: 0.9659090909090909\n",
      "Precision 3: 0.9885057471264368\n",
      "Precision 4: 0.9883720930232558\n",
      "Precision 5: 0.9879518072289156\n",
      "Precision 6: 0.9891304347826086\n",
      "Precision 7: 1.0\n",
      "Precision 8: 0.93\n",
      "Precision 9: 0.9431818181818182\n",
      "Recall 0: 1.0\n",
      "Recall 1: 0.9368421052631579\n",
      "Recall 2: 0.9883720930232558\n",
      "Recall 3: 0.945054945054945\n",
      "Recall 4: 1.0\n",
      "Recall 5: 0.9761904761904762\n",
      "Recall 6: 1.0\n",
      "Recall 7: 0.9891304347826086\n",
      "Recall 8: 0.96875\n",
      "Recall 9: 0.9880952380952381\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test,model.predict(X_test)))\n",
    "\n",
    "for i in range(len(c_matrix)):\n",
    "    precision = c_matrix[i][i] / sum(c_matrix[i][:])\n",
    "    print(\"Precision {}: {}\".format(i,precision))\n",
    "\n",
    "def sum_num(i):\n",
    "    total = 0\n",
    "    for j in range(10):\n",
    "        total = total + c_matrix[j][i]\n",
    "    return total\n",
    "\n",
    "for i in range(len(c_matrix)):\n",
    "    recall = c_matrix[i][i] / sum_num(i)\n",
    "    print(\"Recall {}: {}\".format(i,recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.3,random_state = 7)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 49  0  1  0  1  0  0  1  3]\n",
      " [ 0  0 53  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 49  0  2  0  0  0  0]\n",
      " [ 0  0  0  0 56  0  1  1  0  0]\n",
      " [ 0  0  0  0  0 47  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 47  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 49  0  0]\n",
      " [ 0  3  1  0  1  4  0  1 52  0]\n",
      " [ 0  0  0  1  0  3  0  0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "c_matrix = confusion_matrix(y_test,model.predict(X_test))\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.95\n",
      "Precision 0: 1.0\n",
      "Precision 1: 0.8909090909090909\n",
      "Precision 2: 1.0\n",
      "Precision 3: 0.9423076923076923\n",
      "Precision 4: 0.9655172413793104\n",
      "Precision 5: 0.9791666666666666\n",
      "Precision 6: 0.9791666666666666\n",
      "Precision 7: 1.0\n",
      "Precision 8: 0.8387096774193549\n",
      "Precision 9: 0.9259259259259259\n",
      "Recall 0: 1.0\n",
      "Recall 1: 0.9423076923076923\n",
      "Recall 2: 0.9636363636363636\n",
      "Recall 3: 0.9607843137254902\n",
      "Recall 4: 0.9824561403508771\n",
      "Recall 5: 0.8245614035087719\n",
      "Recall 6: 0.9791666666666666\n",
      "Recall 7: 0.9607843137254902\n",
      "Recall 8: 0.9454545454545454\n",
      "Recall 9: 0.9433962264150944\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test,model.predict(X_test)))\n",
    "\n",
    "for i in range(c_matrix.shape[0]):\n",
    "    precision = c_matrix[i][i] / sum(c_matrix[i][:])\n",
    "    print(\"Precision {}: {}\".format(i,precision))\n",
    "\n",
    "def sum_num(i):\n",
    "    total = 0\n",
    "    for j in range(10):\n",
    "        total = total + c_matrix[j][i]\n",
    "    return total\n",
    "\n",
    "for i in range(c_matrix.shape[0]):\n",
    "    recall = c_matrix[i][i] / sum_num(i)\n",
    "    print(\"Recall {}: {}\".format(i,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
